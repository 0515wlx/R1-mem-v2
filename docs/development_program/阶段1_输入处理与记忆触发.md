### 阶段1：输入处理与记忆触发

#### 技术实现

1. **输入文本处理**  
   - 使用BERT模型对输入文本进行编码，提取语义特征。BERT模型的[CLS]向量（即第一个标记的隐藏状态）被用作文本的语义表示。

2. **记忆索引与检索**  
   - 系统使用Faiss库构建基于语义向量的记忆索引。当输入文本的语义向量满足触发条件时，系统会从记忆库中检索出与当前输入最相关的Top5记忆片段。
   - Titans模型中，记忆检索通过前向传播（不更新权重）实现：  
     \[
     y_t = M^*(q_t)
     \]
     其中，\(q_t = x_t W_q\) 是查询的投影。

3. **动态触发条件判断**  
   - **语义熵**：衡量输入文本的语义模糊性。如果语义熵大于0.6，说明输入文本的语义较为模糊，需要调用记忆来辅助理解。
   - **梯度方差**：监控推理过程中的梯度变化。如果梯度方差小于0.1，说明推理过程可能陷入停滞，需要借助记忆来推动推理。

#### 关键点

1. **混合检索策略**  
   - 系统同时支持关键词匹配和向量检索，既能精确匹配特定记忆，又能通过语义相似性找到相关记忆。

2. **惊喜度量触发**  
   - Titans模型通过惊喜度量（Surprise Metric）决定哪些信息需要存储。惊喜度量定义为模型对输入的梯度，梯度越大表示输入越具“惊喜性”。
   - 更新公式为：  
     \[
     M_t = M_{t-1} + S_t
     \]
     \[
     S_t = \eta_t S_{t-1} - \theta_t \nabla \mathcal{L}(M_{t-1}; x_t)
     \]  
     其中，\(\eta_t\) 控制惊喜的衰减，\(\theta_t\) 控制当前惊喜的影响。